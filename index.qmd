---
title: "Garbage Can Regression Challenge"
format:
  html: default
execute:
  echo: false
  eval: true
---

# Garbage Can Regression Challenge

**Choose R or Python and delete the other code chunk.**

## Python Code

```{python}
#| echo: true
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score
import statsmodels.api as sm

# Data with known true relationships: Anxiety = Stress + 0.1 × Time
data = {
    'Stress': [0,0,0,1,1,1,2,2,2,8,8,8,12,12,12],
    'StressSurvey': [0,0,0,3,3,3,6,6,6,9,9,9,12,12,12],
    'Time': [0,1,1,1,1,1,2,2,2,2,2,2.1,2.2,2.2,2.2],
    'Anxiety': [0,0.1,0.1,1.1,1.1,1.1,2.2,2.2,2.2,8.2,8.2,8.21,12.22,12.22,12.22]
}

observDF = pd.DataFrame(data)
print(observDF)
```

## Your Analysis

### Bivariate Regression: Anxiety on StressSurvey

```{python}
#| echo: true
# Manual bivariate regression of Anxiety on StressSurvey
X = observDF['StressSurvey'].values
y = observDF['Anxiety'].values

# Calculate regression coefficients manually
n = len(X)
sum_x = np.sum(X)
sum_y = np.sum(y)
sum_xy = np.sum(X * y)
sum_x2 = np.sum(X * X)

# Slope (beta1) = (n*sum_xy - sum_x*sum_y) / (n*sum_x2 - sum_x*sum_x)
slope = (n * sum_xy - sum_x * sum_y) / (n * sum_x2 - sum_x * sum_x)

# Intercept (beta0) = (sum_y - beta1*sum_x) / n
intercept = (sum_y - slope * sum_x) / n

# Calculate R-squared
y_pred = intercept + slope * X
ss_res = np.sum((y - y_pred) ** 2)
ss_tot = np.sum((y - np.mean(y)) ** 2)
r_squared = 1 - (ss_res / ss_tot)

print("Regression Results:")
print(f"Intercept (beta0): {intercept:.4f}")
print(f"Slope (beta1): {slope:.4f}")
print(f"R-squared: {r_squared:.4f}")

# Compare to true relationship
print()
print("Comparison to True Relationship:")
print("True relationship: Anxiety = Stress + 0.1 × Time")
print(f"True coefficient of Stress: 1.0")
print(f"Estimated coefficient of StressSurvey: {slope:.4f}")
print(f"Difference from true: {abs(slope - 1.0):.4f}")
```

### Question 1: What are the estimated coefficients? How do they compare to the true coefficients

The estimated coefficients are 1.0470 for the StressSurvey (slope) and -1.5240 for the intercept. The true coefficients are 1.0 for the stress, 0 for the intercept, and 0.1 for the Time. The difference from the true coefficients is 0.0470 for StressSurvey and -1.5240 for the intercept. This tells me that the StressSurvey is a good proxy for the true Stress variable, but the intercept is not a good proxy for the true intercept as it is not 0.

### Scatter Plot with Regression Line

```{python}
#| echo: true
# Create scatter plot with regression line
plt.figure(figsize=(10, 6))
plt.scatter(observDF['StressSurvey'], observDF['Anxiety'], alpha=0.7, s=100, color='blue', label='Data Points')

# Plot regression line
x_range = np.linspace(observDF['StressSurvey'].min(), observDF['StressSurvey'].max(), 100)
y_pred_line = intercept + slope * x_range
plt.plot(x_range, y_pred_line, 'r-', linewidth=2, label=f'Regression Line (y = {intercept:.3f} + {slope:.3f}x)')

plt.xlabel('StressSurvey', fontsize=12)
plt.ylabel('Anxiety', fontsize=12)
plt.title('Relationship between StressSurvey and Anxiety', fontsize=14, fontweight='bold')
plt.legend()
plt.grid(True, alpha=0.3)
plt.tight_layout()
plt.show()

# Additional analysis
print("Fit Analysis:")
print(f"R-squared: {r_squared:.4f} ({r_squared*100:.1f}% of variance explained)")
print(f"Root Mean Square Error: {np.sqrt(ss_res/n):.4f}")
print(f"Mean Absolute Error: {np.mean(np.abs(y - y_pred)):.4f}")

# Check for potential issues
print("\nPotential Issues Analysis:")
print("1. Clustering: Notice the data points cluster at specific StressSurvey values (0, 3, 6, 9, 12)")
print("2. Limited variability: Most variation occurs at discrete levels rather than continuous")
print("3. Perfect linear pattern: The relationship appears artificially perfect")
```

### Question 2: Commentary on Fit and Potential Issues

**Model Fit Assessment:**

The fit is pretty good with a R-squared of 90.11%. The root mean square error is 0.7828 and the mean absolute error is 0.6241. This tells me that the model is a good fit for the data. The data points are scattered around the regression line and the residuals are not clustered at any specific time value. This is a good sign as it suggests that the model is a good fit for the data.

---

### Bivariate Regression: Anxiety on Time

```{python}
#| echo: true
# Manual bivariate regression of Anxiety on Time
X_time = observDF['Time'].values
y_time = observDF['Anxiety'].values

# Calculate regression coefficients manually
n_time = len(X_time)
sum_x_time = np.sum(X_time)
sum_y_time = np.sum(y_time)
sum_xy_time = np.sum(X_time * y_time)
sum_x2_time = np.sum(X_time * X_time)

# Slope (beta1) = (n*sum_xy - sum_x*sum_y) / (n*sum_x2 - sum_x*sum_x)
slope_time = (n_time * sum_xy_time - sum_x_time * sum_y_time) / (n_time * sum_x2_time - sum_x_time * sum_x_time)

# Intercept (beta0) = (sum_y - beta1*sum_x) / n
intercept_time = (sum_y_time - slope_time * sum_x_time) / n_time

# Calculate R-squared
y_pred_time = intercept_time + slope_time * X_time
ss_res_time = np.sum((y_time - y_pred_time) ** 2)
ss_tot_time = np.sum((y_time - np.mean(y_time)) ** 2)
r_squared_time = 1 - (ss_res_time / ss_tot_time)

print("Regression Results (Anxiety on Time):")
print(f"Intercept (beta0): {intercept_time:.4f}")
print(f"Slope (beta1): {slope_time:.4f}")
print(f"R-squared: {r_squared_time:.4f}")

# Compare to true relationship
print()
print("Comparison to True Relationship:")
print("True relationship: Anxiety = Stress + 0.1 × Time")
print(f"True coefficient of Time: 0.1")
print(f"Estimated coefficient of Time: {slope_time:.4f}")
print(f"Difference from true: {abs(slope_time - 0.1):.4f}")

# Create scatter plot for Time vs Anxiety
plt.figure(figsize=(10, 6))
plt.scatter(observDF['Time'], observDF['Anxiety'], alpha=0.7, s=100, color='green', label='Data Points')

# Plot regression line
x_range_time = np.linspace(observDF['Time'].min(), observDF['Time'].max(), 100)
y_pred_line_time = intercept_time + slope_time * x_range_time
plt.plot(x_range_time, y_pred_line_time, 'r-', linewidth=2, label=f'Regression Line (y = {intercept_time:.3f} + {slope_time:.3f}x)')

plt.xlabel('Time', fontsize=12)
plt.ylabel('Anxiety', fontsize=12)
plt.title('Relationship between Time and Anxiety', fontsize=14, fontweight='bold')
plt.legend()
plt.grid(True, alpha=0.3)
plt.tight_layout()
plt.show()

print(f"\nFit Analysis:")
print(f"R-squared: {r_squared_time:.4f} ({r_squared_time*100:.1f}% of variance explained)")
print(f"Root Mean Square Error: {np.sqrt(ss_res_time/n_time):.4f}")
print(f"Mean Absolute Error: {np.mean(np.abs(y_time - y_pred_time)):.4f}")
```

### Question 3: What are the estimated coefficients? How do they compare to the true relationship?

The estimated coefficients are 5.3406 for the time and -3.6801 for the intercept. The true coefficients are 0.1 for the time and 0 for the intercept. The difference from the true coefficients is 5.2406 for the time and -3.6801 for the intercept. This tells me that the time is a good proxy for the true time, but the intercept is not a good proxy for the true intercept as it is not 0.

### Scatter Plot with Regression Line: Time vs Anxiety

```{python}
#| echo: true
# Create scatter plot with regression line for Time vs Anxiety
plt.figure(figsize=(10, 6))
plt.scatter(observDF['Time'], observDF['Anxiety'], alpha=0.7, s=100, color='green', label='Data Points')

# Plot regression line
x_range_time = np.linspace(observDF['Time'].min(), observDF['Time'].max(), 100)
y_pred_line_time = intercept_time + slope_time * x_range_time
plt.plot(x_range_time, y_pred_line_time, 'r-', linewidth=2, label=f'Regression Line (y = {intercept_time:.3f} + {slope_time:.3f}x)')

plt.xlabel('Time', fontsize=12)
plt.ylabel('Anxiety', fontsize=12)
plt.title('Relationship between Time and Anxiety', fontsize=14, fontweight='bold')
plt.legend()
plt.grid(True, alpha=0.3)
plt.tight_layout()
plt.show()

# Additional analysis
print("Fit Analysis:")
print(f"R-squared: {r_squared_time:.4f} ({r_squared_time*100:.1f}% of variance explained)")
print(f"Root Mean Square Error: {np.sqrt(ss_res_time/n_time):.4f}")
print(f"Mean Absolute Error: {np.mean(np.abs(y_time - y_pred_time)):.4f}")

# Check for potential issues
print("\nPotential Issues Analysis:")
print("1. Clustering: Notice the data points cluster at specific Time values (0, 1, 2, 2.1, 2.2)")
print("2. Limited variability: Most variation occurs at discrete levels rather than continuous")
print("3. Poor fit: R-squared of 56.3% indicates Time alone is not a strong predictor")
print("4. Large residuals: Substantial prediction errors throughout the range")
```

### Question 4: Commentary on Fit and Potential Issues

The fit is not very good with a R-squared of 56.3%. The root mean square error is 3.0933 and the mean absolute error is 2.5607. This tells me that the model is not a good fit for the data. The data points are clustered at specific Time values (0, 1, 2, 2.1, 2.2) and the residuals are not random. This is a bad sign as it suggests that the model is not a good fit for the data.

---

### Multiple Regression: Anxiety on StressSurvey and Time

```{python}
#| echo: true
# Multiple regression of Anxiety on both StressSurvey and Time
# Using matrix algebra for multiple regression: β = (X'X)^(-1)X'y

# Create design matrix X with intercept, StressSurvey, and Time
X_multi = np.column_stack([
    np.ones(len(observDF)),  # Intercept column
    observDF['StressSurvey'].values,  # StressSurvey column
    observDF['Time'].values  # Time column
])

y_multi = observDF['Anxiety'].values

# Calculate coefficients using normal equation: β = (X'X)^(-1)X'y
X_transpose = X_multi.T
X_transpose_X = np.dot(X_transpose, X_multi)
X_transpose_X_inv = np.linalg.inv(X_transpose_X)
X_transpose_y = np.dot(X_transpose, y_multi)
coefficients = np.dot(X_transpose_X_inv, X_transpose_y)

# Extract coefficients
intercept_multi = coefficients[0]
slope_stress_survey = coefficients[1]
slope_time = coefficients[2]

# Calculate predictions and R-squared
y_pred_multi = np.dot(X_multi, coefficients)
ss_res_multi = np.sum((y_multi - y_pred_multi) ** 2)
ss_tot_multi = np.sum((y_multi - np.mean(y_multi)) ** 2)
r_squared_multi = 1 - (ss_res_multi / ss_tot_multi)

print("Multiple Regression Results:")
print(f"Intercept (β₀): {intercept_multi:.4f}")
print(f"StressSurvey coefficient (β₁): {slope_stress_survey:.4f}")
print(f"Time coefficient (β₂): {slope_time:.4f}")
print(f"R-squared: {r_squared_multi:.4f}")

# Compare to true relationship
print()
print("Comparison to True Relationship:")
print("True relationship: Anxiety = Stress + 0.1 × Time")
print(f"True coefficient of Stress: 1.0")
print(f"True coefficient of Time: 0.1")
print()
print(f"Estimated StressSurvey coefficient: {slope_stress_survey:.4f}")
print(f"Difference from true Stress: {abs(slope_stress_survey - 1.0):.4f}")
print()
print(f"Estimated Time coefficient: {slope_time:.4f}")
print(f"Difference from true Time: {abs(slope_time - 0.1):.4f}")

# Additional fit statistics
print(f"\nFit Analysis:")
print(f"R-squared: {r_squared_multi:.4f} ({r_squared_multi*100:.1f}% of variance explained)")
print(f"Root Mean Square Error: {np.sqrt(ss_res_multi/len(y_multi)):.4f}")
print(f"Mean Absolute Error: {np.mean(np.abs(y_multi - y_pred_multi)):.4f}")

# Create 3D scatter plot
from mpl_toolkits.mplot3d import Axes3D
fig = plt.figure(figsize=(12, 8))
ax = fig.add_subplot(111, projection='3d')

# Scatter plot
ax.scatter(observDF['StressSurvey'], observDF['Time'], observDF['Anxiety'], 
           c='blue', alpha=0.7, s=100, label='Data Points')

# Create mesh for regression plane
stress_range = np.linspace(observDF['StressSurvey'].min(), observDF['StressSurvey'].max(), 10)
time_range = np.linspace(observDF['Time'].min(), observDF['Time'].max(), 10)
Stress_mesh, Time_mesh = np.meshgrid(stress_range, time_range)
Anxiety_pred = intercept_multi + slope_stress_survey * Stress_mesh + slope_time * Time_mesh

# Plot regression plane
ax.plot_surface(Stress_mesh, Time_mesh, Anxiety_pred, alpha=0.3, color='red', 
                label='Regression Plane')

ax.set_xlabel('StressSurvey')
ax.set_ylabel('Time')
ax.set_zlabel('Anxiety')
ax.set_title('Multiple Regression: Anxiety = f(StressSurvey, Time)')
plt.tight_layout()
plt.show()
```

### Question 5: What are the estimated coefficients? How do they compare to the true relationship?

The estimated coefficients are 0 for the intercept, 1 for the stress, and .1 for the time. The true coefficients are 0 for the intercept, 1 for the stress, and .1 for the time. The difference from the true coefficients is 0 for the intercept, 0 for the stress, and 0 for the time. This tells me that the model is a perfect fit for the data.

---

### Multiple Regression: Anxiety on TRUE Stress and Time

```{python}
#| echo: true
# Multiple regression of Anxiety on both TRUE Stress and Time
# Using matrix algebra for multiple regression: β = (X'X)^(-1)X'y

# Create design matrix X with intercept, TRUE Stress, and Time
X_multi_true = np.column_stack([
    np.ones(len(observDF)),  # Intercept column
    observDF['Stress'].values,  # TRUE Stress column (not StressSurvey)
    observDF['Time'].values  # Time column
])

y_multi_true = observDF['Anxiety'].values

# Calculate coefficients using normal equation: β = (X'X)^(-1)X'y
X_transpose_true = X_multi_true.T
X_transpose_X_true = np.dot(X_transpose_true, X_multi_true)
X_transpose_X_inv_true = np.linalg.inv(X_transpose_X_true)
X_transpose_y_true = np.dot(X_transpose_true, y_multi_true)
coefficients_true = np.dot(X_transpose_X_inv_true, X_transpose_y_true)

# Extract coefficients
intercept_multi_true = coefficients_true[0]
slope_stress_true = coefficients_true[1]
slope_time_true = coefficients_true[2]

# Calculate predictions and R-squared
y_pred_multi_true = np.dot(X_multi_true, coefficients_true)
ss_res_multi_true = np.sum((y_multi_true - y_pred_multi_true) ** 2)
ss_tot_multi_true = np.sum((y_multi_true - np.mean(y_multi_true)) ** 2)
r_squared_multi_true = 1 - (ss_res_multi_true / ss_tot_multi_true)

print("Multiple Regression Results (TRUE Variables):")
print(f"Intercept (β₀): {intercept_multi_true:.4f}")
print(f"Stress coefficient (β₁): {slope_stress_true:.4f}")
print(f"Time coefficient (β₂): {slope_time_true:.4f}")
print(f"R-squared: {r_squared_multi_true:.4f}")

# Compare to true relationship
print()
print("Comparison to True Relationship:")
print("True relationship: Anxiety = Stress + 0.1 × Time")
print(f"True coefficient of Stress: 1.0")
print(f"True coefficient of Time: 0.1")
print(f"True intercept: 0.0")
print()
print(f"Estimated Stress coefficient: {slope_stress_true:.4f}")
print(f"Difference from true Stress: {abs(slope_stress_true - 1.0):.4f}")
print()
print(f"Estimated Time coefficient: {slope_time_true:.4f}")
print(f"Difference from true Time: {abs(slope_time_true - 0.1):.4f}")
print()
print(f"Estimated intercept: {intercept_multi_true:.4f}")
print(f"Difference from true intercept: {abs(intercept_multi_true - 0.0):.4f}")

# Additional fit statistics
print(f"\nFit Analysis:")
print(f"R-squared: {r_squared_multi_true:.4f} ({r_squared_multi_true*100:.1f}% of variance explained)")
print(f"Root Mean Square Error: {np.sqrt(ss_res_multi_true/len(y_multi_true)):.4f}")
print(f"Mean Absolute Error: {np.mean(np.abs(y_multi_true - y_pred_multi_true)):.4f}")

# Create 3D scatter plot with TRUE variables
from mpl_toolkits.mplot3d import Axes3D
fig = plt.figure(figsize=(12, 8))
ax = fig.add_subplot(111, projection='3d')

# Scatter plot
ax.scatter(observDF['Stress'], observDF['Time'], observDF['Anxiety'], 
           c='blue', alpha=0.7, s=100, label='Data Points')

# Create mesh for regression plane
stress_range_true = np.linspace(observDF['Stress'].min(), observDF['Stress'].max(), 10)
time_range_true = np.linspace(observDF['Time'].min(), observDF['Time'].max(), 10)
Stress_mesh_true, Time_mesh_true = np.meshgrid(stress_range_true, time_range_true)
Anxiety_pred_true = intercept_multi_true + slope_stress_true * Stress_mesh_true + slope_time_true * Time_mesh_true

# Plot regression plane
ax.plot_surface(Stress_mesh_true, Time_mesh_true, Anxiety_pred_true, alpha=0.3, color='red', 
                label='Regression Plane')

ax.set_xlabel('Stress (TRUE)')
ax.set_ylabel('Time')
ax.set_zlabel('Anxiety')
ax.set_title('Multiple Regression: Anxiety = f(Stress, Time)\nPerfect Fit (R² = 1.000)')
plt.tight_layout()
plt.show()
```

### Questions to answer for 85% Grade on Challenge:

### Question 4: What are the estimated coefficients? How do they compare to the true relationship?

The estimated coefficients are 0 for the intercept, 1 for the stress, and .1 for the time. These are the same as the true coefficients. The true relationship is Anxiety = Stress + 0.1 × Time. These estimateed coefficents demonstrate that the model is a perfect fit for the data. Using true stress rather than stress survey results in a perfect fit.


### Question 5: Commentary on Fit and Potential Issues

